%! suppress = LineBreak

\subsection{Insertion Sort}\label{subsec:insertion-sort-laufzeit}

\subsubsection{Komplexität im Average und Worst Case}
In Abbildung~\ref{fig:isort} ist die Laufzeit mit zufälligen Zahlen und
aufsteigenden Zahlen zu sehen.
Der Plot sieht auf den ersten Blick quadratisch aus.
Diese Vermutungen bestätigt sich beim Betrachten von
Abbildung~\ref{fig:qsort-complexity-log}, in der die Messung mit zufälligen
Zahlen als Log-Log-Plot dargestellt ist. Da die Steigung der Kurve ähnlich
der Steigung der quadratischen Funktion ist, lässt sich daraus schließen,
dass eine quadratische Komplexität vorliegt.

Dies bestätigt unsere Vermutungen aus dem Entwurf.
\begin{figure}[hbt]
    \centering
    \caption{Insertion Sort}
    \subfloat[average case, worst case]{
    \includegraphics[width = 0.47\textwidth]
    {../out/isort.pdf}\label{fig:isort} }
    \hfill
    \subfloat[best case]{
    \includegraphics[width = 0.47\textwidth]
    {../out/isortBest.pdf}\label{fig:isort-best} }
\end{figure}

\subsubsection{Komplexität im Best-Case}
Der Best-Case ist in Abbildung~\ref{fig:isort-best} dargestellt.
Dieser tritt auf, wenn die Liste absteigend sortiert ist.
Dies lässt sich an der Erlang Implementation erklären, da bei absteigenden
Zahlen mit der \textit{insertToList()} Methode jeweils kleinere Zahlen in den
sortieren Abschnitt eingefügt werden.
Diese Operation hat eine Komplexität von \(\Theta(1)\), da die kleinere Zahl
der Liste vorangestellt wird.
Somit ergibt sich bei absteigenden Zahlen eine Gesamtkomplexität von
\(\Theta(n)\), da dieser diese Methode für alle Elemente der Liste ein Mal
ausgeführt wird.

Bei aufsteigenden Zahlen muss die \textit{insertToList()} Methode hingegen
jeweils bis zum Ende des sortieren Abschnitts laufen, da die Elemente jeweils
größer werden, wodurch eine Gesamtkomplexität von \(\Theta (n^2)\) entsteht.

Zusammenfassen haben wir also festgestellt, dass sich die Laufzeit unserer
Implementation von Insertion Sort durch \(O(n^2)\) und \(\Omega(n)\)
beschreiben lässt, was unseren Erwartungen entspricht.

\subsection{Quick Sort}\label{subsec:quick-sort-laufzeit}
Zur Analyse der finalen Implementation, überspringe bis
Abschnitt~\ref{subsubsec:qsort-pivots}.

\subsubsection{Pivot Methoden - Anfängliche Probleme}

\paragraph{Erste Implementation}
Bei der ersten Implementation vom Quicksort Algorithmus ist bei der
Verwendung der Pivot-Methoden \(right\) und \(median\)  eine deutlich längere
Laufzeit aufgefallen (siehe Abbildung~\ref{fig:qsort-first-impl}).
Gleichzeit ist die Laufzeit von der \(middle\) Pivot Methode besser, obwohl
die Erwartung dieser schlechter ist:
Diese muss eineinhalb mal -- einmal zum Finden der Länge \(l\) komplett, danach
bis zum \(l/2\) Element -- durchlaufen werden.
Die Pivot Methode \(right\) muss nur einmal bis zum Ende der Liste laufen.

\begin{figure}[hbt]
    \caption{Vergleich der Pivot Methoden -- erste Implementation}
    \centering
    \includegraphics[width = 8cm]
    {../out/pivotMethods_Implementation1.pdf}\label{fig:qsort-first-impl}
\end{figure}

Unsere erste Vermutung war, dass unsere Methoden, die in einem
Durchlauf die Länge und gleichzeitig dass Pivot-Element ermitteln dafür
verantwortlich sein könnten.
In der Methoden zum Finden des letzten Elementes, die auch von der median
Pivot Methode verwendet wird, benutzten wir Pattern Matching, um zwischen dem
Letzten und vorletztem Element zu unterscheiden.
Dabei muss allerdings jeweils vorausgeschaut werden, was die schlechte
Performance erklären könnte.

Somit die Vermutung, dass man die Performance verbessern kann, indem man
zunächst die Länge der Liste ermittelt und anschließend diese zum Finden des
n-ten Elements ein zweites Mal durchläuft.

\paragraph{Zweite Implementation}

In der zweiten Implementation wurden die Ermittlung des Pivots und das Finden
der Länge der Liste getrennt.
Das letzte Element wurde nun ermittelt, indem zunächst
die Länge \(l\) der Liste berechnet, anschließend mithilfe dieser zum
\(l-1\) -ten Element gelaufen wird.
\begin{figure}[hbt]
    \centering
    \caption{Zweite Implementation vs. erste Implementation}
    \subfloat[median]{
    \includegraphics[width = 0.47\textwidth]
    {../out/pivotMethods_Implementation2b.pdf}\label{fig:qsort-impl2b} }
    \hfill
    \subfloat[right]{
    \includegraphics[width = 0.47\textwidth]
    {../out/pivotMethods_Implementation2a.pdf}\label{fig:qsort-impl2a} }
\end{figure}


In Abbildung~\ref{fig:qsort-impl2b} und~\ref{fig:qsort-impl2a} sind jeweils die
Ergebnisse der Laufzeitmessung der zweiten Implementation von \(median\) und
\(right\) zu sehen.
Damit systematische Unterschiede zwischen den beiden Kompilationen
ausgeschlossen sind, ist zusätzlich die gleiche Implementation, von \(middle\)
dargestellt.
Bei beiden überarbeiteten Implementationen ist keine Besserung der Laufzeit zu
erkennen, was darauf schließen lässt, dass das in der ersten Implementation
verwendete Pattern Matching nicht der Grund der schlechten Performance war.

\paragraph{Weitere Mögliche Ursachen}
Eine weitere mögliche Ursache für die Ergebnisse ist der Fakt, das bei der
Methode zum Finden des n-ten Elementes und des Restes
\textit{listGetNthAndRest()} die Erlang List Concatenation (\(++\)) verwendet
wird, und somit bei jedem Rekursionsschritt ein zusätzlicher Aufwand von
\(n\), wobei \(n\) die Anzahl der Elemente in der Subliste darstellt,
hinzukommt.
Dies würde auch erklären, warum \textit{middle} eine bessere Laufzeit
aufweist, da dabei nur ein zusätzlicher Aufwand von \(n/2\) halbe dazukommt.

\paragraph{Dritte Implementation}
In der dritten Implementation wurde die List Concatenation ersetzt.

\begin{figure}[hbt]
    \centering
    \caption{Dritte Implementation vs. erste Implementation}
    \includegraphics[width=8cm]
    {../out/pivotMethods_Implementation3.pdf}\label{fig:qsort-impl3}
\end{figure}

Wie in Abbildung~\ref{fig:qsort-impl3} zu sehen,
verbessert dies die Laufzeit dramatisch.
Die Laufzeit der Pivot Methode \textit{middle} hat sich auch verbessert, was
darauf zurückzuführen ist, dass diese ebenfalls die \textit{listGetNthAndRest
()} Methode verwendet.

\subsubsection{Vergleich der Pivot Methoden}\label{subsubsec:qsort-pivots}

In Abbildung~\ref{fig:qsort-impl3-2} ist die Laufzeit der Pivot Methoden der
dritten Implementation mit zufälligen Zahlen dargestellt.
Der Worst-Case ist des Weitern in Abschnitt~\ref{subsubsec:switch-number},
insbesondere in Abbildung~\ref{fig:qsort-switchWorst} dargestellt.

Die Pivot Methoden \textit{left} und \textit{random} weisen die beste
Laufzeit auf, die Methoden \texit{median} und \texit{right} die schlechteste.
Die Laufzeit von \textit{middle} liegt zwischen den anderen.

\paragraph{Right und Median}
Die schlechte Laufzeit von \textit{right} und \textit{median} lässt sich
dadurch erklären, dass die Liste zum Finden des Pivots insgesamt zweimal
komplett durchlaufen wird:
Zunächst zum Finden der Länge, anschließend zum Finden des letzten Elementes.

\paragraph{Middle}
Bei \textit{middle} wird die Liste nur eineinhalb Mal durchlaufen, da beim
zweiten Durchlauf nur bis zur Mitte gelaufen wird.
Dies erklärt die bessere Laufzeit im Vergleich zu den obigen Methoden.

\paragraph{Left und Random}
Die gute Laufzeit von \textit{left} lässt sich dadurch erklären, dass diese bei
zufälligen Zahlen den geringsten Aufwand benötigt, da die Liste zum Finden
des Pivots nicht durchlaufen werden muss.

Die fast identische Laufzeit von \textit{random} ist jedoch überraschend, da
dabei schließlich im Mittel zusätzlich bis zum \(\dfrac{n}{2}\) Element gelaufen
wird.
Somit scheint \textit{random} eine gute Alternative zu \textit{left} zu sein,
da dadurch der Worst-Case von \textit{left} (aufsteigend sortierten Listen)
umgangen wird.


\begin{figure}[hbt]
    \centering
    \caption{Vergleiche der Pivot Methoden -- Dritte Implementation}
    \includegraphics[width=8cm]
    {../out/pivotMethods.pdf}\label{fig:qsort-impl3-2}
\end{figure}

\FloatBarrier

\subsubsection{Switch Number}\label{subsubsec:switch-number}
Bei der Implementation des Quicksort-Algorithmus wird ein Parameter
\textit{switchnumber} übergeben, welches den Schwellenwert angibt, ab wann
von Quicksort auf Insertion Sort umgeschaltet werden soll.

\paragraph{Average Case}
In Abbildung~\ref{fig:qsort-switchPivot} sind
jeweils Laufzeitmessungen mit variierender \textit{switchnumber} zu sehen.
Es wird deutlich, dass im Average-Case die optimale \textit{switchnumber} bei
ca. 20--50 Elementen liegt.

Interessant ist dabei auch, dass die optimale \textit{switchnumber} mit den
effizienteren Pivot Methoden niedriger ist, als mit den ineffizienteren.
Das lässt sich damit erklären, dass bei letzteren der Overhead pro Iteration
größer ist.
Da Insertion Sort einen geringen Aufwand pro Iteration aufweist, ist dieser
trotz schlechterer Komplexität länger im Vorteil.

\paragraph{Worst Case}
In Abbildung~\ref{fig:qsort-switchWorst} ist die \textit{switchnumber} im
Worst-Case von Quicksort untersucht worden.
An den Daten zu absteigenden Zahlen befindet sich Insertion Sort im Best-Case
und hat somit eine Laufzeit von \(\Omega(n)\), dies erklärt, warum der
Verlauf mit zunehmender \textit{switchnumber} scheinbar gegen 0ms läuft.
(Zu Details zum Best-Case von Insertion Sort, siehe
Abbildung~\ref{fig:isort-best} in
Abschnitt~\ref{subsec:insertion-sort-laufzeit})

An den Daten zu aufsteigenden Zahlen befindet sich Insertion Sort im
Average-Case und hat eine Komplexität von \(O(n^2)\).
Da Quicksort im Worst-Case ebenfalls eine Komplexität von \(O(n^2)\)
aufweist, wird hierdurch verdeutlicht, dass der Aufwand pro Iteration, also
der Faktor vor dem \(n\), bei Insertion Sort geringer ist als bei Quicksort.

%TODO

\begin{figure}[hbt]
    \centering
    \caption{Vergleich der Switch Number}
    \subfloat[Average Case]{
    \includegraphics[width = 0.47\textwidth]
    {../out/switchPivot.pdf}\label{fig:qsort-switchPivot} }
    \subfloat[Worst Case]{
    \includegraphics[width = 0.47\textwidth]
    {../out/switchWorstCase.pdf}\label{fig:qsort-switchWorst} }
\end{figure}

\subsubsection{Komplexität im Best Case}\label{subsubsec:qsort-best-case}

An dem linearen Plot (Abbildung~\ref{fig:qsort-complexity})
ist kaum zu erkennen, ob eine lineare oder
über-logarithmische Komplexität vorliegt.
Wir haben uns erhofft, dies mithilfe eines Log-Log-Plots
(Abbildung~\ref{fig:qsort-complexity-log}) genauer zu untersuchen.
Auf solchem ist anhand der Steigung des Graphen der Exponent zu erkennen.
Somit müsste die Steigung unserer Messkurve zwischen den beiden Funktionen
\(f(x)=x\) und \(f(x)=x^2\) liegen, falls diese über-logarithmisch ist.

Leider lässt sich auch auf diesem nicht zwischen dem linearen und, nach
unserer Erwartung, über-logarithmischen Messkurve unterscheiden.

\begin{figure}[hbt]
    \centering
    \caption{Best Case}
    \subfloat[Linearer Plot]{
    \includegraphics[width = 0.47\textwidth]
    {../out/complexity.pdf}\label{fig:qsort-complexity} }
    \subfloat[Log-Log Plot]{
    \includegraphics[width = 0.47\textwidth]
    {../out/complexityLog.pdf}\label{fig:qsort-complexity-log} }
\end{figure}

\subsubsection{Komplexität im Worst Case}\label{subsubsec:worst-case}
Die Laufzeit zum Worst Case wurde kurz im
Abschnitt~\ref{subsubsec:switch-number} besprochen.
Aus zeitlichen Gründen werden wir nicht weiter darauf eingehen.

% TODO avg kann so niedrig sein, weil aufsteigend, heißt keine Varianz der
%zahlen
% hier eigentlich vergleich von isort und qsort
% right, absteigend geht auf null, da die isort laufzeit von sortierten
% listen thetha(n) (?) ist

\FloatBarrier

\subsection{Heap Sort}\label{subsec:heap-sort-laufzeit}

In Abbildung~\ref{fig:hsort2} ist die Laufzeit von Heapsort mit zufälligen
Zahlen, absteigenden Zahlen und aufsteigenden Zahlen dargestellt.
In diesem Test geht es zunächst darum, das Komplexitätsverhalten von Heapsort
zu untersuchen und weitergehend den Vergleich zwischen Heap- und Quicksort
abzubilden.

\begin{figure}[hbt]
    \centering
    \caption{Heapsort}
    \subfloat[Heapsort]{
    \includegraphics[width = 0.47\textwidth]
    {../out/hsort.pdf}\label{fig:hsort2} }
    \subfloat[Heapsort und Quicksort]{
    \includegraphics[width = 0.47\textwidth]
    {../out/hsortqsort.pdf}\label{fig:Vergleich} }
\end{figure}

\subsubsection{Komplexität im Avg Case}\label{subsec:Komplexitaet im
Average-Case}

Betrachten wir zunächst den Average-Case von Heapsort.
Hier wurden zufällig generierte Listen verwendet, um eine durchschnittliche
Laufzeit-Komplexität zu ermitteln.
Anders als in Abbildung~\ref{fig:qsort-complexity}, in der es ohne Regression
nicht möglich ist, Aussagen über das Komplexitätsverhalten zu treffen, lässt
sich in Abbildung~\ref{fig:hsort2} mit bloßem Auge eine Krümmung der Kurve
erkennen.
Dies deutet auf die von uns erwartete Laufzeit von \(O(n\cdot log\ n)\) hin.

\subsubsection{Komplexität im Best Case}\label{subsec:Komplexitaet im Best-Case}

Außerdem in Abbildung~\ref{fig:hsort2} zu sehen ist der Best-Case.
Hier sind die Ergebnisse ein wenig interessanter.

Zunächst betrachten wir jene Ergebnisse die unseren Erwartungen entsprechen.
Der bei einem Heapsort übliche Best-Case ist eine invertiert-sortierte Liste,
also eine Liste von absteigenden Zahlen.
Beim Heapsort spielt das Bauen von und Operieren auf einem Max-Heap eine
zentrale Rolle.
Das größte Element ist die Wurzel des Heaps und die Elemente werden abwärts
immer kleiner.
Da dieser Struktur eine absteigende Anordnung von Zahlen in einer Liste am
nächsten kommt, sollte hier das Bauen des Max-Heaps die effizienteste
Laufzeit besitzen.

Unerwartete Ergebnisse erhalten wir jedoch beim Sortieren einer bereits
sortierten bzw. aufsteigend-sortierten Liste.
Da die Struktur des binären Max-Heaps eher einer absteigenden Liste ähnlich
ist und dies einen kleineren Aufwand beim Erstellen des Heaps mit sich bringt,
ließ sich
ein gegenteilig grosser Aufwand bei einer aufsteigenden Liste vermuten.
Dies ist jedoch nicht der Fall gewesen.
In Abbildung~\ref{fig:hsort2} lässt sich aufsteigend klar eine bessere
Laufzeit erkennen als absteigend, ob wohl absteigend intuitiv als effizienter
hervortritt.

Ergründen lässt sich dies in der Natur unserer Implementierung und dem
Verlauf unseres Projektes.
Zunächst erstellten wir im Entwurf des Heapsort-Algorithmus eine
Bottom-Up-Herangehensweise der Max-Heap-Konstruktion.
In der Implementation haben wir uns jedoch für eine Top-Down-Herangehensweise
entschieden.
Wir nehmen stark an, dass sich die Ergebnisse bei einer Implementation des
ursprünglichen Entwurfs mit unseren Erwartungen gedeckt hätten.

\subsubsection{Vergleich mit Quicksort}\label{subsec:Vergleich mit Quicksort}

Für den Vergleich von Quicksort und Heapsort haben wir einerseits bei Quicksort den Worst- und Average-Case und andererseits bei Heapsort die Messungen aus Abbildung~\ref{fig:hsort2} benutzt.

Betrachte Abbildung~\ref{fig:Vergleich}.
Bei zufällig generierten Listen ist Quicksort, wie erwartet, deutlich
performanter.
Bei 10 Mio. Elementen dauert eine Heap-Sortierung schon fast eine Minute,
während Quicksort noch bei unter 10 Sekunden liegt.

Stellt man jedoch den schlechten Bedingungen für Quicksort her, liegt
(aufgrund von der bereits angesprochenen quadratischen Laufzeitkomplexität
von Quicksort im Worst-Case) Heapsort mit der Performanz deutlich vorne. Die
im Entwurf vermuteten Erwartungen sind demnach eingetroffen.



